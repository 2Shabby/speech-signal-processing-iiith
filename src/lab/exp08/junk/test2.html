<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
  
  <meta content="text/html; charset=UTF-8" http-equiv="content-type">
  <title>test</title>

  
</head><body>
<h1><i><i><a> </a></i></i></h1>

<h1>Collection of voiced (/a/)and unvoiced (/s/) speech segments
</h1>

<ul>

  <li>Record a vowel /a/ for one second at 10 KHz sampling frequency
with 16 bit quantization. From this recorded speech file collect 200 ms
in steady portion of the waveform. </li>
  <li>Record an unvoiced segment /s/ for one second at 10 KHz sampling
sampling frequency with 16 bit quantization. From this recorded speech
file collect 200 ms in steady portion of the waveform. </li>
  <li>The short voiced and unvoiced speech segments are shown in
Figure&nbsp;1. </li>
  <li><br>
  </li>
</ul>

<a name="fig:voiced-unvoiced-waveform"></a><a name="183"></a> <img src="file:///home/anand/Course/spTechLabTutorials/texfiles/tut-6/tut-6/img2.png" alt="\resizebox*{15cm}{8cm}{\includegraphics{figures/figure1.eps}}" align="bottom" border="0" height="363" width="681"><br>

<strong>Figure 1:</strong> <i class="sans">(a) Segment of voiced
speech /a/ and (b) segment of unvoiced speech /s/<br>
</i>
<h1>Short time spectrum, LP spectrum and Inverse spectrum for voiced
segment /a/</h1>

<br>

<h2>Short time spectrum</h2>

The short time spectrum consists of range of frequencies (magnitude and
phase components) that are present in a small segment (10-30 ms) of a
signal. Short time spectrum is computed with the following procedure:
<br>

<ul>

  <li>Take 20 ms of voiced speech segment /a/ after preemphasis <br>
    <span style="font-style: italic;">a=wavread('vowel.wav'); </span><br style="font-style: italic;">
    <span style="font-style: italic;">a=diff(a); </span><br style="font-style: italic;">
    <span style="font-style: italic;">a200=a(501:700);</span> </li>
  <li>Apply a hamming window over a voiced segment (a200), then compute
the fast Fourier transform for the voiced segment (a200) and plot the
magnetite of the spectrum. <br>
    <span style="font-style: italic;">ham=hamming(200); </span><br style="font-style: italic;">
    <span style="font-style: italic;">a200ham=a200.*ham; </span><br style="font-style: italic;">
    <span style="font-style: italic;">a200hamspec=fft(a200ham,1024); </span><br style="font-style: italic;">
    <span style="font-style: italic;">y=abs(a200hamspec.*a200hamspec); </span><br style="font-style: italic;">
    <span style="font-style: italic;">logy=10*log10(y); </span><br style="font-style: italic;">
    <span style="font-style: italic;">figure;plot([1:512]*5000/512,logy(1:512));grid;</span>
  </li>
</ul>

<br>

<h2><LP spectrum=""></LP></h2>

<ul>

  <li>LP spectrum provides smoothed envelope of the short time
spectrum, where only the formant frequencies (resonances) are observed.
For realizing this linear prediction coefficients (LPCs) or filter
parameters need to be computed from speech signal. <br>
    <span style="font-style: italic;">ak=lpc(a200,14); </span><br style="font-style: italic;">
    <span style="font-style: italic;">lpspec=freqz(1,ak); </span><br style="font-style: italic;">
    <span style="font-style: italic;">y=abs(lpspec.*lpspec); </span><br style="font-style: italic;">
    <span style="font-style: italic;">logy=10*log10(y); </span><br style="font-style: italic;">
    <span style="font-style: italic;">figure;plot([1:512]*5000/512,logy);grid;
    </span><br>
  </li>
</ul>

<h2> Inverse spectrum </h2>

<ul>

  <li>Inverse filter is realized by the inverse of LP filter. Therefore
the spectrum of the inverse filter is computed as follows: <br>
    <span style="font-style: italic;">invspec=freqz(ak,1); </span><br style="font-style: italic;">
    <span style="font-style: italic;">y=abs(invspec.*invspec); </span><br style="font-style: italic;">
    <span style="font-style: italic;">logy=10*log10(y); </span><br style="font-style: italic;">
    <span style="font-style: italic;">figure;plot([1:512]*5000/512,logy);grid;
    </span><br>
  </li>
</ul>

<p>
The short time spectrum, LP spectrum and inverse spectrum for a segment
of voiced speech are shown in Figure&nbsp;2.
</p>

<a name="fig:voiced-spec"></a><a name="185"></a>
<br>

<img src="file:///home/anand/Course/spTechLabTutorials/texfiles/tut-6/tut-6/img3.png" alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/fig2.eps}}" align="bottom" border="0" height="454" width="680"><br>

<strong>Figure 2:</strong> <i class="sans">(a)
Segment of voiced speech /a/ and its (b) short
time spectrum, (c) LP spectrum and (d) inverse spectrum<br>
</i><br>

<br>

<h1><a name="SECTION00030000000000000000">Short time spectrum, LP
spectrum and Inverse spectrum for unvoiced segment /s/</a>
</h1>

<ul>

  <li>For computing the short time spectrum, LP spectrum and inverse
spectrum for an unvoiced segment /s/ the same procedure is followed as
that of for voiced speech segment /a/. </li>
  <li>The short time spectrum, LP spectrum and inverse spectrum for a
segment of unvoiced speech (/s/) are shown in Figure&nbsp;3. </li>
  <li>Observation: <br>
In short time spectrum envelope no major peaks are observed. Pitch
harmonics (periodic ripples) also not observed. <br>
In LP spec rum sharp peaks are not present and spectrum observed to be
flat. In inverse spectrum also no major events are observed. </li>
</ul>

<img src="../../../../../../../../../Course/spTechLabTutorials/texfiles/tut-6/tut-6/img5.png" alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/fig3.eps}}" align="bottom" border="0" height="454" width="680">
<br>

<a name="fig:unvoiced-spec"></a><a name="187"></a>
<strong>Figure 3:</strong>
<i class="sans">(a) Segment of unvoiced speech /s/ and its (b) short
time spectrum, (c) LP spectrum and (d) inverse spectrum.<br>
<br>
</i>
<h1>LP residual for voiced and unvoiced segments </h1>

<ul>

  <li>LP residual signal is obtained by passing the speech signal
through inverse filter designed with LP coefficients (LPCs). The block
diagram of the inverse filter is shown in Figure&nbsp;4.&nbsp; <img src="../../../../../../../../../Course/spTechLabTutorials/texfiles/tut-6/tut-6/img6.png" alt="\resizebox*{12cm}{3cm}{\includegraphics{figures/inversefilter.eps}}" align="bottom" border="0" height="135" width="543"></li>
</ul>

<strong>Figure 4:</strong> <i class="sans">Inverse filter to obtain LP
residual signal from </i><strong></strong><i class="sans">
speech signal</i>
<ul>

  <li>LP residual is computed for voiced and unvoiced speech segments
using the following matlab commands:&nbsp;</li>
  <ul style="font-style: italic;">
    <li>res=filter(ak,1,a200);&nbsp;</li>
    <li>figure;plot(real(res));grid; <br>
    </li>
  </ul>
  <li>Voiced and unvoiced speech segments and their LP residual signals
are shown in Figure&nbsp;5. </li>
</ul>

&nbsp;
<img src="../../../../../../../../../Course/spTechLabTutorials/texfiles/tut-6/tut-6/img7.png" alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure8.eps}}" align="bottom" border="0" height="454" width="680"><br>

<a name="fig:residuals"></a><a name="191"></a><strong>Figure 5:</strong>
<i class="sans">(a) Segment of voiced speech /a/ and its (b) LP
residual signal, (c) segment of unvoiced speech /s/ and its (d) LP
residual signal.</i><br>

<br>

<br>

<h1>Autocorrelation function for
voiced/unvoiced speech segments and their LP residuals
</h1>

<br>

<ul>

  <li>Autocorrelation function of the signal x(t) is computed using the
following formulation: <br>
    <span class="MATH"><img src="../../../../../../../../../Course/spTechLabTutorials/texfiles/tut-6/tut-6/img8.png" alt="$ R(\tau) = \sum_{t=0}^\infty{x(t)x(t+\tau)}$" align="middle" border="0" height="39" width="209"></span> </li>
  <li>The above formulation is implemented in matlab using the command
xcorr(x(t)). Autocorrelation function for voiced and unvoiced segments
and their LP residuals is computed. <br>
a200corr=xcorr(a200); </li>
  <li>The autocorrelation function for the voiced speech segment and
its LP residual signal is shown in Figure&nbsp;6.</li>
  <br>
  <img src="../../../../../../../../../Course/spTechLabTutorials/texfiles/tut-6/tut-6/img9.png" alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure6.eps}}" align="top" border="0" height="454" width="681"><strong><br>
Figure 6:</strong><i class="sans">(a) Segment of voiced speech /a/ and
its (b)
autocorrelation function, (c) LP residual for the voiced speech segment
and its (d) autocorrelation function. </i><br>
  <br>
  <li>The autocorrelation function for the unvoiced speech segment and
its LP residual signal is shown in Figure&nbsp;7.</li>
  <li><br><img src="../../../../../../../../../Course/spTechLabTutorials/texfiles/tut-6/tut-6/img10.png" alt="\resizebox*{15cm}{10cm}{\includegraphics{figures/figure7.eps}}" align="top" border="0" height="454" width="680"> </li>
  <br>
  <strong>Figure 7:</strong><i class="sans">(a) Segment of unvoiced
speech /s/ and its (b)
autocorrelation function, (c) LP residual for the unvoiced speech
segment and its (d) autocorrelation function. </i>
</ul>

<br>

<br>
</body></html>